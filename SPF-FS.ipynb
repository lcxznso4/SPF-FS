{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "from numpy.linalg import eigh, matrix_rank\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "EPS = 1e-10\n",
    "\n",
    "############################\n",
    "# (A) 数据 & 第一阶段筛选\n",
    "############################\n",
    "\n",
    "def preprocess_data(file, min_samples=3):\n",
    "    \"\"\"\n",
    "    1) 过滤在 min_samples 个样本中表达 > 0 的基因\n",
    "    2) log(1+x) 转换\n",
    "    返回 X: shape=(d,n), df_normalized: DataFrame(行=样本, 列=基因)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file, index_col=0)\n",
    "    # 过滤\n",
    "    df_filtered = df.loc[:, (df > 0).sum(axis=0) >= min_samples]\n",
    "    # 对数归一化\n",
    "    df_normalized = np.log1p(df_filtered)\n",
    "    # 转置 => X.shape=(d,n)\n",
    "    X = df_normalized.values.T\n",
    "    return X, df_normalized\n",
    "\n",
    "def compute_variance_score(X):\n",
    "    \"\"\"\n",
    "    简易方差打分\n",
    "    X: (d,n)\n",
    "    返回每个基因(行)的方差\n",
    "    \"\"\"\n",
    "    return np.var(X, axis=1)\n",
    "\n",
    "############################\n",
    "# (B) 多指标打分 + Leiden => 基结果\n",
    "############################\n",
    "\n",
    "def compute_hvg_scores(X_subset):\n",
    "    \"\"\"\n",
    "    基于方差的 HVG 打分\n",
    "    X_subset: (d, n_sub)\n",
    "    \"\"\"\n",
    "    var_ = np.var(X_subset, axis=1)\n",
    "    scores = (var_ - var_.min()) / (var_.max() - var_.min() + EPS)\n",
    "    return scores\n",
    "\n",
    "def compute_fano_scores(X_subset):\n",
    "    \"\"\"\n",
    "    Fano 因子打分\n",
    "    \"\"\"\n",
    "    mean_ = np.mean(X_subset, axis=1) + EPS\n",
    "    var_  = np.var(X_subset, axis=1)\n",
    "    fano  = var_ / mean_\n",
    "    scores= (fano - fano.min()) / (fano.max() - fano.min() + EPS)\n",
    "    return scores\n",
    "\n",
    "def compute_gmm_scores(X_subset):\n",
    "    \"\"\"\n",
    "    用 GaussianMixture(n=1 vs n=2) 的 BIC差计算打分\n",
    "    \"\"\"\n",
    "    d,_ = X_subset.shape\n",
    "    gmm_score= np.zeros(d)\n",
    "    for i in range(d):\n",
    "        data_i = X_subset[i,:].reshape(-1,1)\n",
    "\n",
    "        gm1= GaussianMixture(n_components=1, random_state=0).fit(data_i)\n",
    "        gm2= GaussianMixture(n_components=2, random_state=0).fit(data_i)\n",
    "        bic1= gm1.bic(data_i)\n",
    "        bic2= gm2.bic(data_i)\n",
    "        diff= bic1 - bic2\n",
    "        # 若差值>0 表示 n=2 成分模型更优 => 打分更高\n",
    "        gmm_score[i]= max(diff, 0.0)\n",
    "\n",
    "    # 归一化\n",
    "    gmm_score = (gmm_score - gmm_score.min()) / (gmm_score.max() - gmm_score.min() + EPS)\n",
    "    return gmm_score\n",
    "\n",
    "def spearman_distance_matrix(X):\n",
    "    \"\"\"\n",
    "    计算 Spearman 距离矩阵, X:(d,n) => ranks => 1-corr => dist\n",
    "    \"\"\"\n",
    "    X_t = X.T   # shape=(n,d)\n",
    "    # 对每行做排序 => rank\n",
    "    ranks = np.argsort(np.argsort(X_t, axis=1), axis=1).astype(float)\n",
    "    # 去中心化\n",
    "    rc = ranks - ranks.mean(axis=1, keepdims=True)\n",
    "    cov= rc @ rc.T\n",
    "    norm_ = np.linalg.norm(rc, axis=1, keepdims=True)\n",
    "    corr = cov/(norm_ * norm_.T + EPS)\n",
    "    dist = 1 - corr\n",
    "    return dist\n",
    "\n",
    "def construct_knn_graph(dist, k=10):\n",
    "    \"\"\"\n",
    "    基于距离矩阵构造 kNN 图, 对称化\n",
    "    dist: (n,n)\n",
    "    返回 adj_sym: (n,n)\n",
    "    \"\"\"\n",
    "    n= dist.shape[0]\n",
    "    adj= np.zeros((n,n), dtype=float)\n",
    "    for i in range(n):\n",
    "        idx_sorted= np.argsort(dist[i,:])\n",
    "        neighbors= idx_sorted[1:k+1]\n",
    "        adj[i, neighbors] = 1\n",
    "    adj_sym= np.maximum(adj, adj.T)\n",
    "    return adj_sym\n",
    "\n",
    "def leiden_clustering(adj, resolution=1.0):\n",
    "    \"\"\"\n",
    "    在给定邻接矩阵上做 Leiden 聚类\n",
    "    \"\"\"\n",
    "    adata= anndata.AnnData(np.zeros((adj.shape[0],1)))\n",
    "    A_csr= csr_matrix(adj)\n",
    "    adata.obsp[\"connectivities\"] = A_csr\n",
    "    adata.uns[\"neighbors\"]={}\n",
    "    adata.uns[\"neighbors\"][\"connectivities_key\"]=\"connectivities\"\n",
    "    sc.tl.leiden(adata, resolution=resolution, key_added='leiden')\n",
    "    labels= adata.obs['leiden'].astype(int).values\n",
    "    return labels\n",
    "\n",
    "def compute_base_result_leiden(i, X, select_ratio=0.5, k=10, resolution=1.0):\n",
    "    \"\"\"\n",
    "    1) 随机抽取 50% 样本 => HVG, Fano, GMM 得分合并 => v^(k)\n",
    "    2) 按得分选 top 50% 基因 => Spearman => kNN => Leiden => S^(k)\n",
    "    \"\"\"\n",
    "    d,n= X.shape\n",
    "    idx_sub= np.random.choice(n, size=int(0.5*n), replace=False)\n",
    "    X_sub= X[:, idx_sub]\n",
    "\n",
    "    # 三种打分\n",
    "    s1= compute_hvg_scores(X_sub)\n",
    "    s2= compute_fano_scores(X_sub)\n",
    "    s3= compute_gmm_scores(X_sub)\n",
    "    combined= (s1+s2+s3)/3.0\n",
    "\n",
    "    # 选前 50% 基因\n",
    "    num_select= int(d * select_ratio)\n",
    "    idx_sel= np.argsort(combined)[-num_select:]\n",
    "    X_sel= X[idx_sel, :]\n",
    "\n",
    "    dist= spearman_distance_matrix(X_sel)\n",
    "    adj= construct_knn_graph(dist, k=k)\n",
    "    labels= leiden_clustering(adj, resolution=resolution)\n",
    "\n",
    "    S_k= lil_matrix((n,n))\n",
    "    n_label= np.max(labels) + 1\n",
    "    for c in range(n_label):\n",
    "        members= np.where(labels==c)[0]\n",
    "        S_k[np.ix_(members, members)] = 1\n",
    "\n",
    "    return combined, S_k.tocsr()\n",
    "\n",
    "def generate_base_results_leiden(X, m=10, select_ratio=0.5, k=10, resolution=1.0):\n",
    "    \"\"\"\n",
    "    生成 m 个基学习器的 (scores, connectivity) 对\n",
    "    \"\"\"\n",
    "    base_scores=[]\n",
    "    base_connectivity=[]\n",
    "    for i in range(m):\n",
    "        scr, conn= compute_base_result_leiden(i, X, select_ratio, k=k, resolution=resolution)\n",
    "        base_scores.append(scr)\n",
    "        base_connectivity.append(conn)\n",
    "    return base_scores, base_connectivity\n",
    "\n",
    "############################\n",
    "# (B2) GO BP 富集后 p值 => 先验 w\n",
    "############################\n",
    "\n",
    "def run_gobp_enrichment(gene_list):\n",
    "    \"\"\"\n",
    "    将原先的远程 enrichr 替换为本地离线富集\n",
    "    使用 c5.go.bp.v2024.1.Hs.symbols.gmt 文件来做 GO-BP 分析\n",
    "    \"\"\"\n",
    "    import gseapy\n",
    "\n",
    "    # 假设 c5.go.bp.v2024.1.Hs.symbols.gmt 与本脚本在同一目录\n",
    "    # 如果在其它路径, 请自行修改下方路径\n",
    "    local_gmt_path = \"data/c5.go.bp.v2024.1.Hs.symbols.gmt\"\n",
    "\n",
    "    enr = gseapy.enrichr(\n",
    "        gene_list = gene_list,         # 基因列表\n",
    "        gene_sets = local_gmt_path,    # 指向本地 GMT 文件\n",
    "        outdir    = None,             # 不保存到硬盘, 仅保留内存\n",
    "        cutoff    = 1.0               # p-value 截断\n",
    "        # enrichr_url=None,           # 一般不用也行, 只要 gene_sets=本地文件就不会远程\n",
    "    )\n",
    "    enr.run()\n",
    "    return enr.res2d\n",
    "\n",
    "def define_additive_prior_gobp(gene_list, p_cut=0.05):\n",
    "    \"\"\"\n",
    "    对 gene_list 做 GO:BP 富集, 将最小 P-value 映射到 [0.2,0.8]\n",
    "    \"\"\"\n",
    "    res_df= run_gobp_enrichment(gene_list)\n",
    "    gene2p= {g:1.0 for g in gene_list}\n",
    "    if len(res_df)>0:\n",
    "        for _,row in res_df.iterrows():\n",
    "            p= row[\"P-value\"]\n",
    "            genes_in_term= row[\"Genes\"].replace(\" \",\"\").split(\";\")\n",
    "            for gg in genes_in_term:\n",
    "                gene2p[gg] = min(gene2p.get(gg,1.0), p)\n",
    "\n",
    "    w=[]\n",
    "    for g in gene_list:\n",
    "        p= gene2p[g]\n",
    "        if p> p_cut:\n",
    "            w.append(0.2)\n",
    "        else:\n",
    "            ratio= (p_cut - p)/ p_cut\n",
    "            val= 0.2 + 0.6* ratio\n",
    "            w.append(val)\n",
    "    return np.array(w)\n",
    "\n",
    "def generate_base_priors_gobp(X, base_scores, gene_names, p_cut=0.05, ratio_for_enrich=0.5):\n",
    "    \"\"\"\n",
    "    对每个基结果 v^(k):\n",
    "      1) 选出前 (ratio_for_enrich*d) 基因\n",
    "      2) GO富集 => 映射成 w_sub\n",
    "      3) 映射回 d维, 其余默认填0.2\n",
    "    \"\"\"\n",
    "    m = len(base_scores)\n",
    "    d = len(gene_names)\n",
    "    base_priors = []\n",
    "\n",
    "    for k in range(m):\n",
    "        scr = base_scores[k]\n",
    "        num_sel = int(d * ratio_for_enrich)\n",
    "        idx_sel = np.argsort(scr)[-num_sel:]\n",
    "\n",
    "        gene_sub_list = gene_names[idx_sel].tolist()\n",
    "        w_sub = define_additive_prior_gobp(gene_sub_list, p_cut=p_cut)\n",
    "\n",
    "        w_all = np.full(d, 0.2, dtype=float)\n",
    "        for i_sub, g_idx in enumerate(idx_sel):\n",
    "            w_all[g_idx] = w_sub[i_sub]\n",
    "        base_priors.append(w_all)\n",
    "\n",
    "    return np.array(base_priors)\n",
    "\n",
    "############################\n",
    "# (C) 自进学习 & 其他更新函数\n",
    "############################\n",
    "\n",
    "def update_S(W, base_connectivity, P, X, v, Y, beta, rho):\n",
    "    \"\"\"\n",
    "    更新共识邻接矩阵 S (不含簇间分离项)\n",
    "    \"\"\"\n",
    "    m=len(base_connectivity)\n",
    "    n=X.shape[1]\n",
    "    dv= np.sqrt(v+EPS)\n",
    "    D_v= np.diag(dv)\n",
    "    weighted_X= D_v@X\n",
    "    Z= P@weighted_X\n",
    "    Z2= np.sum(Z**2, axis=0)\n",
    "    B= np.add.outer(Z2,Z2) - 2*(Z.T@Z)\n",
    "\n",
    "    Y2= np.sum(Y**2, axis=1)\n",
    "    C= np.add.outer(Y2,Y2) - 2*(Y@Y.T)\n",
    "\n",
    "    beta_sum= np.sum(beta**2)\n",
    "    S_acc= np.zeros((n,n))\n",
    "    for k in range(m):\n",
    "        S_acc += (beta[k]**2)* base_connectivity[k].toarray()\n",
    "\n",
    "    W_plus= 2*W*beta_sum + EPS\n",
    "    numerator= S_acc - B + rho*C\n",
    "    S_new= numerator / W_plus\n",
    "    S_new= np.clip(S_new,0,1)\n",
    "\n",
    "    from scipy.sparse import csr_matrix\n",
    "    return csr_matrix(S_new)\n",
    "\n",
    "def update_W(S, base_connectivity, beta, lam):\n",
    "    \"\"\"\n",
    "    更新自步学习权重矩阵 W\n",
    "    W_(i,j) = min{1, lambda / (2*∑(beta_k^2 * (S - S^(k))^2)) }\n",
    "    \"\"\"\n",
    "    m=len(base_connectivity)\n",
    "    S_d=S.toarray()\n",
    "    A= np.zeros_like(S_d)\n",
    "    for k in range(m):\n",
    "        diff= S_d - base_connectivity[k].toarray()\n",
    "        A+= (beta[k]**2)*(diff**2)\n",
    "    W= np.minimum(lam / (2*(A+EPS)), 1)\n",
    "    return W\n",
    "\n",
    "def update_alpha(v, base_scores):\n",
    "    \"\"\"\n",
    "    α_k ∝ 1 / (‖v - v^(k)‖^2 + eps)\n",
    "    \"\"\"\n",
    "    m=len(base_scores)\n",
    "    arr= np.zeros(m)\n",
    "    for k in range(m):\n",
    "        dist= np.linalg.norm(v - base_scores[k])**2\n",
    "        arr[k]= 1.0/(dist + EPS)\n",
    "    alpha= arr/(arr.sum() + EPS)\n",
    "    return alpha\n",
    "\n",
    "def update_beta(S, base_connectivity, W):\n",
    "    \"\"\"\n",
    "    β_k ∝ 1 / (‖W⊙(S - S^(k))‖_F^2 + eps)\n",
    "    \"\"\"\n",
    "    m=len(base_connectivity)\n",
    "    S_d= S.toarray()\n",
    "    arr= np.zeros(m)\n",
    "    for k in range(m):\n",
    "        diff= W*(S_d - base_connectivity[k].toarray())\n",
    "        val= np.linalg.norm(diff,'fro')**2\n",
    "        arr[k]= 1.0/(val + EPS)\n",
    "    beta= arr/(arr.sum() + EPS)\n",
    "    return beta\n",
    "\n",
    "############################\n",
    "# (C2) 特征向量合并\n",
    "############################\n",
    "\n",
    "def update_u_for_each_base(base_scores, base_priors, gamma):\n",
    "    \"\"\"\n",
    "    计算 u^(k) = v^(k) + gamma * w^(k), 并做 clip+归一化\n",
    "    \"\"\"\n",
    "    m= len(base_scores)\n",
    "    u_list= []\n",
    "    for k in range(m):\n",
    "        v_k= base_scores[k]\n",
    "        w_k= base_priors[k]\n",
    "        u_k= v_k + gamma*w_k\n",
    "\n",
    "        # clip & 归一化\n",
    "        u_k= np.clip(u_k, 0, None)\n",
    "        sum_uk= u_k.sum() + EPS\n",
    "        u_k/= sum_uk\n",
    "        u_list.append(u_k)\n",
    "    return u_list\n",
    "\n",
    "def update_v_with_u(X, u_list, alpha):\n",
    "    \"\"\"\n",
    "    在单纯形约束下求解  min_v Σ( alpha_k^2 * ||v - u^(k)||^2 )\n",
    "    \"\"\"\n",
    "    import cvxpy as cp\n",
    "    m= len(u_list)\n",
    "    d= X.shape[0]\n",
    "    v_var= cp.Variable(d, nonneg=True)\n",
    "\n",
    "    objective= 0\n",
    "    for k in range(m):\n",
    "        objective += alpha[k]**2 * cp.sum_squares(v_var - u_list[k])\n",
    "\n",
    "    constraints= [cp.sum(v_var)==1, v_var<=1]\n",
    "    prob= cp.Problem(cp.Minimize(objective), constraints)\n",
    "    prob.solve(solver=cp.ECOS, verbose=False)\n",
    "\n",
    "    if v_var.value is None:\n",
    "        v_new= np.ones(d)/d\n",
    "    else:\n",
    "        v_new= np.maximum(v_var.value, 0)\n",
    "        sum_v= v_new.sum() + EPS\n",
    "        v_new/= sum_v\n",
    "    return v_new\n",
    "\n",
    "############################\n",
    "# (C3) 原先的 update_P, update_Y (不含簇间)\n",
    "############################\n",
    "\n",
    "def update_P(X,v,S,n_clusters):\n",
    "    \"\"\"\n",
    "    
    "    \"\"\"\n",
    "    d,n= X.shape\n",
    "    dv= np.sqrt(v+EPS)\n",
    "    D_v= np.diag(dv)\n",
    "    S_d= S.toarray()\n",
    "    D= np.diag(S_d.sum(axis=1))\n",
    "    L= D-S_d\n",
    "    M= D_v@X@L@(X.T)@D_v\n",
    "    eigvals,eigvecs= eigh(M)\n",
    "    idx= np.argsort(eigvals)\n",
    "    P= eigvecs[:, idx[:n_clusters]].T\n",
    "    return P\n",
    "\n",
    "def update_Y(S,n_clusters):\n",
    "    \"\"\"\n",
    "   
    "    \"\"\"\n",
    "    S_d= S.toarray()\n",
    "    D= np.diag(S_d.sum(axis=1))\n",
    "    L= D-S_d\n",
    "    eigvals,eigvecs= eigh(L)\n",
    "    idx= np.argsort(eigvals)\n",
    "    Y= eigvecs[:, idx[:n_clusters]]\n",
    "    return Y, L\n",
    "\n",
    "############################\n",
    "# (C4) 簇间分离: update_P_enhanced / update_Y_enhanced\n",
    "############################\n",
    "\n",
    "def update_P_enhanced(X, v, S, Y, eta, n_clusters):\n",
    "    \"\"\"\n",
    "    更新 P, 考虑 -eta * ||y_i - y_j||^2 => W_tilde = S - eta*distY, clip>=0 => L_tilde\n",
    "    \"\"\"\n",
    "    S_d = S.toarray()\n",
    "    n = S_d.shape[0]\n",
    "\n",
    "    # distY[i,j] = ||y_i - y_j||^2\n",
    "    Y2 = np.sum(Y**2, axis=1, keepdims=True)\n",
    "    distY = Y2 + Y2.T - 2*(Y @ Y.T)\n",
    "\n",
    "    W_tilde = S_d - eta * distY\n",
    "    W_tilde = np.clip(W_tilde, 0, None)\n",
    "\n",
    "    D_tilde = np.diag(W_tilde.sum(axis=1))\n",
    "    L_tilde = D_tilde - W_tilde\n",
    "\n",
    "    d,_ = X.shape\n",
    "    dv = np.sqrt(v + EPS)\n",
    "    D_v = np.diag(dv)\n",
    "    M = D_v @ X @ L_tilde @ X.T @ D_v\n",
    "\n",
    "    eigvals, eigvecs= eigh(M)\n",
    "    idx= np.argsort(eigvals)\n",
    "    P= eigvecs[:, idx[:n_clusters]].T\n",
    "    return P\n",
    "\n",
    "def update_Y_enhanced(S, P, X, v, eta, n_clusters):\n",
    "    \"\"\"\n",
    "    更新 Y, 考虑 -eta * ||Z_i - Z_j||^2 => W_tilde = S - eta*distZ, distZ=||Z_i - Z_j||^2\n",
    "    \"\"\"\n",
    "    S_d= S.toarray()\n",
    "    n= S_d.shape[0]\n",
    "\n",
    "    dv= np.sqrt(v+EPS)\n",
    "    D_v= np.diag(dv)\n",
    "    ZX = D_v @ X    # shape=(d,n)\n",
    "    Z  = P @ ZX     # shape=(c,n), Z[:,j] = x_j的映射\n",
    "\n",
    "    Z2 = np.sum(Z**2, axis=0, keepdims=True)\n",
    "    distZ = Z2 + Z2.T - 2*(Z.T @ Z)\n",
    "\n",
    "    W_tilde = S_d - eta*distZ\n",
    "    W_tilde = np.clip(W_tilde, 0, None)\n",
    "\n",
    "    D_tilde = np.diag(W_tilde.sum(axis=1))\n",
    "    L_tilde = D_tilde - W_tilde\n",
    "\n",
    "    eigvals, eigvecs = eigh(L_tilde)\n",
    "    idx = np.argsort(eigvals)\n",
    "    Y= eigvecs[:, idx[:n_clusters]]\n",
    "\n",
    "    return Y, L_tilde\n",
    "\n",
    "############################\n",
    "# (C5) 逐步增大 λ 的主循环\n",
    "############################\n",
    "\n",
    "def BLFSE_intraBio_with_localU(\n",
    "    X,\n",
    "    base_scores,\n",
    "    base_priors,\n",
    "    base_connectivity,\n",
    "    gamma=0.5,\n",
    "    n_clusters=5,\n",
    "    max_iter=10,\n",
    "    eta=0.1,\n",
    "    lambda_init=0.2,     # <-- 初始 λ\n",
    "    lambda_growth=0.3,   # <-- 每轮迭代后以该比例递增\n",
    "    rho=1.0\n",
    "):\n",
    "    \"\"\"\n",
    "    基于双层融合 + 先验 + 自步学习 + 簇间分离 的算法主循环.\n",
    "    每次迭代后 lambda *= (1 + lambda_growth), 使更多样本对被纳入.\n",
    "    \"\"\"\n",
    "    from scipy.sparse import csr_matrix\n",
    "\n",
    "    m= len(base_scores)\n",
    "    d,n= X.shape\n",
    "\n",
    "    # 1) 初始化 v => base_scores平均\n",
    "    v= np.mean(np.array(base_scores), axis=0)\n",
    "    v/= (v.sum() + EPS)\n",
    "\n",
    "    # 初始化共识邻接 S\n",
    "    S_init= np.mean([bc.toarray() for bc in base_connectivity], axis=0)\n",
    "    S= csr_matrix(S_init)\n",
    "\n",
    "    # 初始化 alpha, beta\n",
    "    alpha= np.ones(m)/m\n",
    "    beta= np.ones(m)/m\n",
    "\n",
    "    lam= lambda_init  # 初始 λ\n",
    "\n",
    "    # 给 Y 一个初始值\n",
    "    Y, L = update_Y(S, n_clusters)\n",
    "\n",
    "    for it in range(max_iter):\n",
    "        logging.info(f\"=== Iteration {it+1}/{max_iter}, lambda={lam:.4f} ===\")\n",
    "\n",
    "        # (1) 更新 W (自步学习)\n",
    "        W= update_W(S, base_connectivity, beta, lam)\n",
    "\n",
    "        # (2) 更新 P (增强版, 簇间分离)\n",
    "        P= update_P_enhanced(X, v, S, Y, eta, n_clusters)\n",
    "\n",
    "        # (3) 更新 Y (增强版, 簇间分离)\n",
    "        Y, L_tilde = update_Y_enhanced(S, P, X, v, eta, n_clusters)\n",
    "\n",
    "        # (4) 更新 S\n",
    "        S= update_S(W, base_connectivity, P, X, v, Y, beta, rho)\n",
    "\n",
    "        # (5) 更新特征向量 v: u^(k)= v^(k)+gamma*w^(k), 再投影\n",
    "        u_list= update_u_for_each_base(base_scores, base_priors, gamma=gamma)\n",
    "        v= update_v_with_u(X, u_list, alpha)\n",
    "\n",
    "        # (6) 更新 alpha, beta\n",
    "        alpha= update_alpha(v, base_scores)\n",
    "        beta= update_beta(S, base_connectivity, W)\n",
    "\n",
    "        # (7) 逐步增大 lambda\n",
    "        lam *= (1.0 + lambda_growth)\n",
    "\n",
    "        # 若要近似 rank(D-S)=n-c, 可自适应 rho:\n",
    "        # r= matrix_rank(L_tilde)\n",
    "        # if r> n-n_clusters: rho *= 2\n",
    "        # elif r< n-n_clusters: rho /= 2\n",
    "\n",
    "    return v, S, P, Y, alpha, beta\n",
    "\n",
    "############################\n",
    "# (D) main 函数\n",
    "############################\n",
    "\n",
    "def main():\n",
    "    # 你可以替换为自己的数据文件\n",
    "    data_file= \"./data/pollen_counts.csv\"\n",
    "\n",
    "    X_full, df_full= preprocess_data(data_file, min_samples=3)\n",
    "    d_full, n= X_full.shape\n",
    "    logging.info(f\"Data => genes={d_full}, samples={n}\")\n",
    "\n",
    "    # 1) 根据方差筛选 top2000\n",
    "    var_all= compute_variance_score(X_full)\n",
    "    topN=2000\n",
    "    idx_top= np.argsort(var_all)[-topN:]\n",
    "    X_2000= X_full[idx_top,:]\n",
    "    gene_names_2000= df_full.columns[idx_top]\n",
    "    logging.info(f\"Selected top {topN} genes by variance\")\n",
    "\n",
    "    # 2) 生成基结果 (HVG,Fano,GMM+Leiden)\n",
    "    m=10\n",
    "    base_scores, base_conn= generate_base_results_leiden(\n",
    "        X_2000, m=m, select_ratio=0.5, k=10, resolution=1.0\n",
    "    )\n",
    "\n",
    "    # 3) 生成 GO 先验 (离线模式)\n",
    "    #   - p_cut 可设小一些, 强化对显著功能条目的聚焦\n",
    "    base_priors= generate_base_priors_gobp(\n",
    "        X_2000,\n",
    "        base_scores,\n",
    "        gene_names_2000,\n",
    "        p_cut=1e-5,       # 比较严格的阈值\n",
    "        ratio_for_enrich=0.5\n",
    "    )\n",
    "    logging.info(\"Generated base_priors from local GO BP enrichment (offline).\")\n",
    "\n",
    "    # 4) 调用改进版 BLFSE, 设定 lambda 初始值和增长率\n",
    "    v_final, S_final, P_final, Y_final, alpha_final, beta_final= BLFSE_intraBio_with_localU(\n",
    "        X_2000,\n",
    "        base_scores,\n",
    "        base_priors,\n",
    "        base_conn,\n",
    "        gamma=1,\n",
    "        n_clusters=11,\n",
    "        max_iter=10,\n",
    "        eta=0.2,\n",
    "        lambda_init=0.2,\n",
    "        lambda_growth=0.3\n",
    "    )\n",
    "\n",
    "    # 5) 导出选出的基因\n",
    "    outdir = \"./spf-只使用HVG\"\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    for topN_final in [400]:\n",
    "        if topN_final > X_2000.shape[0]:\n",
    "            logging.warning(f\"topN_final={topN_final} > #genes({X_2000.shape[0]}) => skip.\")\n",
    "            continue\n",
    "\n",
    "        idx_sel = np.argsort(v_final)[-topN_final:]\n",
    "        sel_genes = gene_names_2000[idx_sel]\n",
    "        logging.info(f\"Top {topN_final} genes => {sel_genes[:10].tolist()} ...\")\n",
    "\n",
    "        X_sel = X_2000[idx_sel, :].T\n",
    "        sel_df = pd.DataFrame(X_sel, columns=sel_genes, index=df_full.index)\n",
    "\n",
    "        outname = f\"{outdir}/pollen1_methodB_GOBP_top{topN_final}.csv\"\n",
    "        sel_df.to_csv(outname)\n",
    "        logging.info(f\"Saved => {outname}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
